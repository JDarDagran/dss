{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed8fe58-1aef-44ba-93a6-423d05d3cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (SparkSession.builder.master('local').appName('dss_spark')\n",
    "        # Install and set up the OpenLineage listener\n",
    "        .config('spark.jars.packages', 'io.openlineage:openlineage-spark_2.12:1.24.2,org.postgresql:postgresql:42.2.18')\n",
    "        .config('spark.extraListeners', 'io.openlineage.spark.agent.OpenLineageSparkListener')\n",
    "        .config('spark.openlineage.transport.url', 'http://marquez-api:5000')\n",
    "        .config('spark.openlineage.transport.type', 'http')\n",
    "        .config('spark.openlineage.namespace', 'spark_integration')\n",
    "        .enableHiveSupport()\n",
    "        .getOrCreate())\n",
    "\n",
    "\n",
    "spark.sql('CREATE DATABASE IF NOT EXISTS public')\n",
    "\n",
    "spark.sql('''CREATE TABLE IF NOT EXISTS speakers (\n",
    "    speaker_id INT,\n",
    "    name VARCHAR(255),\n",
    "    bio STRING\n",
    ");''')\n",
    "    \n",
    "spark.sql(\"\"\"CREATE TABLE IF NOT EXISTS sessions (\n",
    "    session_id INT,\n",
    "    title VARCHAR(255),\n",
    "    speaker_id INT,\n",
    "    start_time TIMESTAMP,\n",
    "    end_time TIMESTAMP\n",
    ");\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"CREATE TABLE IF NOT EXISTS attendees (\n",
    "    attendee_id INT,\n",
    "    name VARCHAR(255),\n",
    "    email VARCHAR(255),\n",
    "    session_id INT\n",
    ");\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"INSERT INTO speakers (speaker_id, name, bio)\n",
    "VALUES \n",
    "(1, 'John Smith', 'John is a renowned expert in the field of data science'),\n",
    "(2, 'Jane Doe', 'Jane is a leading researcher in machine learning'),\n",
    "(3, 'Bob Johnson', 'Bob is a seasoned industry professional with expertise in Python'),\n",
    "(4, 'Jakub Dardzinski', 'Just a random guy')\n",
    ";\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "INSERT INTO sessions (session_id, title, speaker_id, start_time, end_time)\n",
    "VALUES (1, 'Introduction to Data Science', 1, timestamp('2024-11-22 09:00:00'), timestamp('2024-11-22 10:30:00')),\n",
    "       (2, 'Machine Learning with Python', 2, timestamp('2024-11-22 10:45:00'), timestamp('2024-11-22 12:15:00')),\n",
    "       (3, 'Big Data and Analytics', 3, timestamp('2024-11-22 13:30:00'), timestamp('2024-11-22 15:00:00')),\n",
    "       (4, 'Make Data Science Great', 1, timestamp('2024-11-22 15:00:00'), timestamp('2024-11-22 15:30:00')),\n",
    "       (5, 'OpenLineage: Easy Way to Unlock Your Data Potential', 4, timestamp('2024-11-22 15:30:00'), timestamp('2024-11-22 16:00:00')),\n",
    "       (6, 'Machine Learning Unlocked', 2, timestamp('2024-11-22 16:30:00'), timestamp('2024-11-22 17:00:00'))\n",
    ";\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"INSERT INTO attendees (attendee_id, name, email, session_id)\n",
    "VALUES \n",
    "(1, 'Alice Brown', 'alicebrown@example.com', 1),\n",
    "(2, 'Bob Davis', 'bobdavis@example.com', 2),\n",
    "(3, 'Charlie Wilson', 'charliewilson@example.com', 3)\n",
    ";\"\"\")\n",
    "\n",
    "df = spark.sql(\"\"\"SELECT s.session_id, COUNT(a.attendee_id) AS attendees_count\n",
    "FROM sessions s\n",
    "JOIN attendees a ON s.session_id = a.session_id\n",
    "GROUP BY s.session_id;\"\"\")\n",
    "\n",
    "df.write.mode(\"overwrite\").saveAsTable('public.attendees_by_session')\n",
    "\n",
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://postgres/airflow\") \\\n",
    "    .option(\"dbtable\", \"public.attendees_by_session\") \\\n",
    "    .option(\"user\", \"airflow\") \\\n",
    "    .option(\"password\", \"airflow\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eeddb19d-e3c1-467c-b08c-221ad34d436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers = spark.read.table(\"sessions\").groupBy(\"speaker_id\").count().sort(\"count\", ascending=False).limit(2)\n",
    "top_speakers.createOrReplaceTempView(\"top_speakers\")\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "SELECT DISTINCT \n",
    "sp.speaker_id,\n",
    "sp.name, s.session_id\n",
    "FROM speakers sp\n",
    "JOIN sessions s ON s.speaker_id = sp.speaker_id\n",
    "WHERE sp.speaker_id IN (SELECT speaker_id FROM top_speakers)\n",
    "ORDER BY sp.name, s.session_id\n",
    ";\"\"\")\n",
    "\n",
    "df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://postgres/airflow\") \\\n",
    "    .option(\"dbtable\", \"public.top_speakers\") \\\n",
    "    .option(\"user\", \"airflow\") \\\n",
    "    .option(\"password\", \"airflow\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9905385-9748-4faa-91b7-060a3e44980b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
